{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dv is 1.0000454187393188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15787/3645033109.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax(A), F.softmax(A)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1.1548e-17, 4.5398e-05, 4.2482e-18, 9.9995e-01, 6.3048e-16, 8.5327e-17,\n",
       "         2.3194e-16, 6.9141e-13], device='cuda:0'),\n",
       " tensor([1.1548e-17, 4.5398e-05, 4.2482e-18, 9.9995e-01, 6.3048e-16, 8.5327e-17,\n",
       "         2.3194e-16, 6.9141e-13], device='cuda:0'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(X: torch.Tensor):\n",
    "    m = X.flatten().clone()\n",
    "    d = torch.ones_like(m)\n",
    "    for i in range(1, m.shape[0]):\n",
    "        mi, mj = m[i-1], m[i]\n",
    "        di, dj = d[i-1], d[i]\n",
    "        new_max = max(mi, mj)\n",
    "        new_sum = di * torch.exp(mi - new_max) + dj * torch.exp(mj - new_max)\n",
    "        # print(torch.exp(mi - t[0][i]).item(), torch.exp(mj - t[0][i]).item())\n",
    "        m[i] = new_max\n",
    "        d[i] = new_sum\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    mv, dv = m[-1], d[-1]\n",
    "    print(f'dv is {dv}')\n",
    "    return (X-mv).exp() / dv.item()\n",
    "\n",
    "\n",
    "A = torch.tensor([1, 30, 0, 40, 5, 3, 4, 12], dtype=torch.float32, device='cuda')\n",
    "softmax(A), F.softmax(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.3890560989306495\n"
     ]
    }
   ],
   "source": [
    "# d is a running sum of exponentiated values\n",
    "\n",
    "m = 2 \n",
    "# d = e^m\n",
    "d = torch.e ** m\n",
    "print(d)\n",
    "\n",
    "# d = e^m -> e^n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No ROCm runtime is found, using ROCM_HOME='/opt/rocm-6.2.0'\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file cuda-build/build.ninja...\n",
      "/home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module m...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=m -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/TH -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /home/seb/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /home/seb/CUDA/flash-attention/online_softmax/main.cpp -o main.o \n",
      "[2/3] /usr/local/cuda-12.3/bin/nvcc --generate-dependencies-with-compile --dependency-output softmax.cuda.o.d -DTORCH_EXTENSION_NAME=m -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/TH -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /home/seb/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_61,code=compute_61 -gencode=arch=compute_61,code=sm_61 --compiler-options '-fPIC' -std=c++17 -c /home/seb/CUDA/flash-attention/online_softmax/softmax.cu -o softmax.cuda.o \n",
      "/home/seb/CUDA/flash-attention/online_softmax/softmax.cu(24): warning #177-D: variable \"original_value\" was declared but never referenced\n",
      "      float original_value;\n",
      "            ^\n",
      "\n",
      "Remark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "[3/3] c++ main.o softmax.cuda.o -shared -L/home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda-12.3/lib64 -lcudart -o m.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module m...\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.cpp_extension import load\n",
    "module = load(\n",
    "    name='m',\n",
    "    sources=['main.cpp', 'softmax.cu'],\n",
    "    verbose=True,\n",
    "    build_directory='cuda-build'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dv is 19.02651023864746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.0222, 0.0452, 0.0366, 0.0484, 0.7041, 0.7839, 0.3832, 0.4354, 0.7191,\n",
       "         0.4597, 0.3467, 0.4764, 0.1350, 0.8765, 0.7420, 0.2697, 0.6575, 0.1705,\n",
       "         0.2379, 0.1659, 0.3326, 0.9253, 0.7323, 0.8366, 0.2354, 0.7464, 0.3698,\n",
       "         0.7602, 0.9653], device='cuda:0'),\n",
       " tensor([0.0222, 0.0452, 0.0366, 0.0484, 0.0254, 0.0359, 0.0526, 0.0256, 0.0341,\n",
       "         0.0359, 0.0280, 0.0328, 0.0300, 0.0510, 0.0432, 0.0400, 0.0426, 0.0298,\n",
       "         0.0331, 0.0241, 0.0379, 0.0376, 0.0245, 0.0462, 0.0211, 0.0309, 0.0248,\n",
       "         0.0279, 0.0326], device='cuda:0'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.rand(29, device='cuda', dtype=torch.float32)\n",
    "# A = torch.tensor([1, 0, 4, 5], dtype=torch.float32, device='cuda')\n",
    "module.softmax(B), softmax(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stride is 2\n",
    "# Old value = 1.000000, New value = 1.606531\n",
    "# Stride is 1\n",
    "# cuda: mv is 1.000000, dv is 2.342289\n",
    "# mv is 1.0, dv is 4.0\n",
    "16*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
