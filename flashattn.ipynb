{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to use the right version of pytorch when testing on nvidia/amd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "M = 32\n",
    "\n",
    "\n",
    "def flashattn(Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor) -> torch.Tensor:\n",
    "    assert Q.shape == K.shape == V.shape\n",
    "    assert len(Q.shape) == 2\n",
    "\n",
    "    K = K.T\n",
    "\n",
    "    # seq length, inner dim of representations\n",
    "    N, d = Q.shape\n",
    "\n",
    "    # of kv vectors per tile\n",
    "    bc = math.ceil(M/(4*d))\n",
    "    tc = math.ceil(N/bc)\n",
    "    K_shared = torch.empty((d, bc), dtype=Q.dtype)\n",
    "    V_shared = torch.empty((bc, d), dtype=Q.dtype)\n",
    "\n",
    "    # of q vectors per tile\n",
    "    br = min(math.ceil(M/(4*d)), d)\n",
    "    tr = math.ceil(N/br)\n",
    "    Q_shared = torch.empty((br, d), dtype=Q.dtype)\n",
    "\n",
    "    # print(f'bc={bc}, br={br}')\n",
    "    # print(f'tc={tc}, tr={tr}')\n",
    "\n",
    "    # output matrix\n",
    "    O = torch.zeros_like(Q)\n",
    "    O_shared = torch.empty_like(Q_shared)\n",
    "\n",
    "    # intermediate rowmaxes\n",
    "    m = torch.full((N,), -torch.inf, dtype=Q.dtype)\n",
    "    m_shared = torch.empty((br, 1), dtype=Q.dtype)\n",
    "    # intermediate normalization constants\n",
    "    l = torch.full((N,), 0, dtype=Q.dtype)\n",
    "    l_shared = torch.empty((br, 1), dtype=Q.dtype)\n",
    "\n",
    "    for i in range(tc):\n",
    "        # load k, v chunks\n",
    "        # make sure we load in k as its transposed version\n",
    "        K_shared[:, :] = K[:, i*bc:(i+1)*bc]\n",
    "        V_shared[:, :] = V[i*bc:(i+1)*bc, :]\n",
    "\n",
    "        for j in range(tr):\n",
    "            # load in q, o, m, l\n",
    "            Q_shared[:, :] = Q[j*br:(j+1)*br, :]\n",
    "            # if i == 0: print(f'Q: {Q_shared}')\n",
    "            O_shared[:, :] = O[j*br:(j+1)*br, :]\n",
    "            m_shared[:, :] = m[j*br:(j+1)*br].unsqueeze(-1)\n",
    "            l_shared[:, :] = l[j*br:(j+1)*br].unsqueeze(-1)\n",
    "            \n",
    "            S = Q_shared @ K_shared\n",
    "\n",
    "            # get row-wise softmax statistics\n",
    "            mt = S.max(dim=1).values.reshape(-1, 1)\n",
    "\n",
    "            Pt = torch.exp(S - mt)\n",
    "            lt = Pt.sum(dim=1).reshape(-1, 1)\n",
    "\n",
    "            # compute new statistics\n",
    "            m_new = torch.max(mt, m_shared)\n",
    "            l_new = (torch.exp(m_shared - m_new) * l_shared) + (torch.exp(mt - m_new) * lt)\n",
    "\n",
    "\n",
    "            # update chunk of output\n",
    "            O_new = (l_shared * torch.exp(m_shared - m_new) * O_shared + torch.exp(mt - m_new) * Pt @ V_shared) / l_new\n",
    "            O[j*br:(j+1)*br, :] = O_new\n",
    "            \n",
    "            m[j*br:(j+1)*br] = m_new.flatten()\n",
    "            l[j*br:(j+1)*br] = l_new.flatten()\n",
    "\n",
    "    return O\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[26.1250, 33.8438, 38.0938,  ..., 14.1016,  9.5391, 17.1719],\n",
       "         [39.3438, 33.8750, 17.5000,  ..., 10.9844, 18.5625,  9.3672],\n",
       "         [15.5625, 41.9688, 13.1484,  ..., 10.0156, 13.5625, 23.1562],\n",
       "         ...,\n",
       "         [29.9062, 22.9531, 29.1719,  ..., 12.8750, 15.2109, 49.6875],\n",
       "         [32.5312, 24.4844, 42.0000,  ..., 11.6172, 42.5625, 27.3750],\n",
       "         [18.4531,  6.2812, 46.1250,  ...,  7.8047,  9.7109, 21.1250]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[26.1406, 27.3906, 40.4375,  ..., 15.6953, 25.4688, 23.0625],\n",
       "         [17.3750, 29.6875, 18.2500,  ..., 17.0469, 25.1719, 36.0000],\n",
       "         [28.2656, 15.1016,  3.8047,  ..., 30.3281, 16.1719, 31.4375],\n",
       "         ...,\n",
       "         [38.6875, 37.0312,  9.2422,  ..., 22.7969, 19.9375,  1.8281],\n",
       "         [ 5.2070, 11.2734, 15.9922,  ..., 21.9531, 19.9531, 39.2188],\n",
       "         [ 6.8047, 33.5312, 29.1719,  ..., 12.3516, 44.3750,  7.8242]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[40.2812, 23.5938, 25.4688,  ..., 18.2500, 14.3594, 14.1016],\n",
       "         [43.2500, 26.4688, 10.0078,  ..., 47.0625, 26.4375,  6.3984],\n",
       "         [47.5938, 35.0625, 12.9609,  ..., 48.8750,  7.5312, 26.8594],\n",
       "         ...,\n",
       "         [11.4609, 43.0312,  4.5703,  ..., 16.4844, 15.9297,  6.5938],\n",
       "         [29.9531, 39.6875,  2.1621,  ..., 33.1875, 45.5938, 21.3750],\n",
       "         [47.6875, 47.2500,  5.6172,  ..., 38.9062, 26.4688, 34.6250]],\n",
       "        device='cuda:0', dtype=torch.float16))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dumb_attn(Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"equivalent to F.scaled_dot_product_attention(Q, K, V, scale=1)\"\"\"\n",
    "    # P = (Q @ K.T)\n",
    "    # m = P.max(dim=1).values.reshape(-1, 1)\n",
    "    # print((P - m).exp())\n",
    "    # return torch.softmax(Q @ K.T, dim=1) @ V\n",
    "    return F.scaled_dot_product_attention(Q, K, V, scale=1)\n",
    "\n",
    "\n",
    "# have to support up to like d=4096\n",
    "# we're giving up and only supporting fp16 (like flashattn)\n",
    "Q = torch.rand((8, 128), dtype=torch.float16, device='cuda') * 50\n",
    "K = torch.rand((8, 128), dtype=torch.float16, device='cuda') * 50\n",
    "V = torch.rand((8, 128), dtype=torch.float16, device='cuda') * 50\n",
    "\n",
    "\n",
    "# Q = torch.randint(1, 9, (8, 4), device='cuda').to(torch.float16)\n",
    "# K = torch.randint(1, 9, (8, 4), device='cuda').to(torch.float16)\n",
    "# V = torch.randint(1, 9, (8, 4), device='cuda').to(torch.float16)\n",
    "\n",
    "# Q = torch.tensor([[0., 1.],\n",
    "#          [2., 3.]])\n",
    "\n",
    "# K = torch.tensor([[0., 1.5],\n",
    "#          [2., 3.]])\n",
    "\n",
    "# V = torch.tensor([[1., 0.],\n",
    "#          [0., 1.]])\n",
    "Q, K, V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/seb/Code/flash-attention/rocm/flash_attention.hip -> /home/seb/Code/flash-attention/rocm/flash_attention_hip.hip [ok]\n",
      "Total number of unsupported CUDA function calls: 0\n",
      "\n",
      "\n",
      "Total number of replaced kernel launches: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input conditions for extension module m have changed. Bumping to version 1 and re-building as m_v1...\n",
      "\u001b[92mSuccessfully preprocessed all matching files.\u001b[0m\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file build/build.ninja...\n",
      "Building extension module m_v1...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] /opt/rocm-6.1.3/bin/hipcc  -DWITH_HIP -DTORCH_EXTENSION_NAME=m_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/seb/Code/pyenvs/rocmenv/lib/python3.12/site-packages/torch/include -isystem /home/seb/Code/pyenvs/rocmenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/seb/Code/pyenvs/rocmenv/lib/python3.12/site-packages/torch/include/TH -isystem /home/seb/Code/pyenvs/rocmenv/lib/python3.12/site-packages/torch/include/THC -isystem /home/seb/Code/pyenvs/rocmenv/lib/python3.12/site-packages/torch/include/THH -isystem /opt/rocm-6.1.3/include -isystem /home/seb/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 --offload-arch=\"gfx1100\" -fPIC -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -fno-gpu-rdc -c /home/seb/Code/flash-attention/rocm/flash_attention_hip.hip -o flash_attention_hip.cuda.o \n",
      "/home/seb/Code/flash-attention/rocm/flash_attention_hip.hip:303:5: warning: ignoring return value of function declared with 'nodiscard' attribute [-Wunused-result]\n",
      "  303 |     hipGetDeviceProperties(&props, 0);\n",
      "      |     ^~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~\n",
      "/opt/rocm-6.1.3/include/hip/hip_runtime_api.h:91:32: note: expanded from macro 'hipGetDeviceProperties'\n",
      "   91 | #define hipGetDeviceProperties hipGetDevicePropertiesR0600\n",
      "      |                                ^~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/home/seb/Code/flash-attention/rocm/flash_attention_hip.hip:335:30: warning: format specifies type 'int' but the argument has type 'size_t' (aka 'unsigned long') [-Wformat]\n",
      "  335 |     printf(\"tc=%d, tr=%d\\n\", tc, tr);\n",
      "      |                ~~            ^~\n",
      "      |                %zu\n",
      "/home/seb/Code/flash-attention/rocm/flash_attention_hip.hip:335:34: warning: format specifies type 'int' but the argument has type 'size_t' (aka 'unsigned long') [-Wformat]\n",
      "  335 |     printf(\"tc=%d, tr=%d\\n\", tc, tr);\n",
      "      |                       ~~         ^~\n",
      "      |                       %zu\n",
      "3 warnings generated when compiling for gfx1100.\n",
      "/home/seb/Code/flash-attention/rocm/flash_attention_hip.hip:303:5: warning: ignoring return value of function declared with 'nodiscard' attribute [-Wunused-result]\n",
      "  303 |     hipGetDeviceProperties(&props, 0);\n",
      "      |     ^~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~\n",
      "/opt/rocm-6.1.3/include/hip/hip_runtime_api.h:91:32: note: expanded from macro 'hipGetDeviceProperties'\n",
      "   91 | #define hipGetDeviceProperties hipGetDevicePropertiesR0600\n",
      "      |                                ^~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/home/seb/Code/flash-attention/rocm/flash_attention_hip.hip:335:30: warning: format specifies type 'int' but the argument has type 'size_t' (aka 'unsigned long') [-Wformat]\n",
      "  335 |     printf(\"tc=%d, tr=%d\\n\", tc, tr);\n",
      "      |                ~~            ^~\n",
      "      |                %zu\n",
      "/home/seb/Code/flash-attention/rocm/flash_attention_hip.hip:335:34: warning: format specifies type 'int' but the argument has type 'size_t' (aka 'unsigned long') [-Wformat]\n",
      "  335 |     printf(\"tc=%d, tr=%d\\n\", tc, tr);\n",
      "      |                       ~~         ^~\n",
      "      |                       %zu\n",
      "3 warnings generated when compiling for host.\n",
      "[2/2] c++ flash_attention_hip.cuda.o -shared -L/home/seb/Code/pyenvs/rocmenv/lib/python3.12/site-packages/torch/lib -lc10 -lc10_hip -ltorch_cpu -ltorch_hip -ltorch -ltorch_python -L/opt/rocm-6.1.3/lib -lamdhip64 -o m_v1.so\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module m_v1...\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.cpp_extension import load\n",
    "module = load(\n",
    "    name='m',\n",
    "    # sources=['cuda/main.cpp', 'cuda/flash_attention.cu'],\n",
    "    sources=['rocm/flash_attention.hip',],\n",
    "    extra_cflags=['--offload-arch=\"gfx1100\"',],\n",
    "    build_directory='build',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shared Memory per Block: 64 KB\n",
      "  Shared Memory Banks: 65536\n",
      "  Warp Size: 32\n",
      "  Max Threads per Block: 1024\n",
      "  Max Threads per Multiprocessor: 2048\n",
      "\n",
      "tc=1, tr=1\n",
      "Launching kernel with smem size 8320\n",
      "[[26.125000, 33.843750, 38.093750, 47.250000, 36.281250, 30.984375, 7.691406, 45.031250, 23.968750, 46.781250, 0.613281, 40.812500, 17.718750, 46.312500, 28.859375, 4.863281, 36.093750, 2.792969, 38.812500, 38.218750, 3.271484, 42.781250, 17.390625, 46.968750, 47.468750, 16.437500, 10.835938, 4.886719, 38.687500, 32.000000, 9.890625, 30.718750, 6.945312, 28.046875, 43.031250, 47.375000, 46.718750, 24.812500, 41.750000, 40.531250, 1.752930, 46.718750, 41.468750, 9.945312, 37.750000, 18.937500, 24.578125, 25.968750, 28.546875, 30.250000, 37.687500, 21.265625, 21.125000, 37.875000, 4.324219, 27.703125, 47.281250, 31.281250, 7.976562, 15.804688, 24.640625, 34.718750, 3.634766, 2.449219, 20.906250, 7.464844, 16.171875, 32.843750, 6.871094, 10.867188, 44.593750, 34.000000, 2.867188, 8.109375, 33.062500, 0.855469, 19.109375, 17.906250, 8.585938, 17.265625, 30.984375, 36.187500, 36.656250, 41.562500, 28.093750, 10.367188, 19.640625, 1.068359, 33.656250, 22.234375, 23.906250, 43.500000, 42.843750, 25.125000, 3.212891, 14.195312, 4.140625, 48.718750, 39.718750, 6.292969, 3.595703, 17.359375, 18.390625, 14.578125, 18.843750, 17.390625, 36.093750, 45.312500, 43.187500, 37.187500, 34.281250, 25.734375, 26.562500, 2.773438, 8.843750, 4.011719, 24.812500, 30.515625, 25.687500, 30.640625, 13.046875, 18.406250, 27.765625, 46.937500, 16.593750, 14.101562, 9.539062, 17.171875, ]\n",
      "[39.343750, 33.875000, 17.500000, 25.687500, 18.609375, 10.476562, 19.671875, 7.304688, 14.453125, 22.171875, 12.593750, 24.640625, 24.937500, 28.875000, 24.515625, 11.046875, 40.875000, 32.500000, 25.609375, 14.718750, 23.609375, 14.585938, 1.013672, 7.707031, 40.187500, 45.906250, 4.847656, 10.250000, 22.843750, 30.203125, 46.718750, 2.406250, 26.640625, 22.750000, 34.812500, 16.656250, 6.542969, 35.500000, 3.830078, 5.019531, 49.250000, 33.625000, 45.687500, 32.343750, 25.828125, 27.765625, 10.625000, 28.031250, 40.156250, 18.937500, 33.312500, 31.812500, 42.062500, 12.648438, 49.843750, 11.953125, 24.562500, 2.242188, 7.464844, 35.218750, 33.156250, 2.103516, 36.406250, 18.328125, 47.468750, 27.296875, 16.750000, 1.798828, 10.914062, 48.687500, 18.718750, 43.656250, 34.812500, 4.199219, 35.968750, 7.996094, 16.828125, 21.515625, 34.500000, 3.216797, 41.343750, 7.062500, 14.187500, 45.031250, 32.281250, 21.296875, 2.191406, 38.906250, 47.812500, 48.093750, 0.766113, 13.000000, 5.617188, 40.468750, 34.093750, 23.671875, 8.054688, 15.445312, 16.640625, 22.312500, 2.804688, 1.586914, 37.218750, 33.750000, 29.421875, 7.734375, 26.375000, 1.316406, 3.472656, 29.375000, 34.437500, 21.625000, 23.000000, 19.078125, 40.000000, 46.625000, 38.312500, 49.468750, 19.953125, 4.699219, 49.062500, 30.500000, 8.515625, 43.406250, 24.953125, 10.984375, 18.562500, 9.367188, ]\n",
      "[15.562500, 41.968750, 13.148438, 25.750000, 7.476562, 24.562500, 7.550781, 10.382812, 18.562500, 35.781250, 35.562500, 16.906250, 31.781250, 42.281250, 1.240234, 22.484375, 24.250000, 43.906250, 33.687500, 33.281250, 14.101562, 32.531250, 9.445312, 32.031250, 26.296875, 6.757812, 29.031250, 3.753906, 34.500000, 17.203125, 2.228516, 21.312500, 29.937500, 31.171875, 25.515625, 21.156250, 11.789062, 12.273438, 30.171875, 11.289062, 46.093750, 3.585938, 12.203125, 9.203125, 31.781250, 40.000000, 9.515625, 30.203125, 23.968750, 17.140625, 24.359375, 7.066406, 11.312500, 5.585938, 29.031250, 9.117188, 10.898438, 48.281250, 1.217773, 22.328125, 21.796875, 46.125000, 49.281250, 34.875000, 49.937500, 0.314697, 33.593750, 26.218750, 7.605469, 11.953125, 9.296875, 3.308594, 6.996094, 44.968750, 20.906250, 20.390625, 19.765625, 16.937500, 46.812500, 49.218750, 17.156250, 44.468750, 45.468750, 6.914062, 17.375000, 15.328125, 8.703125, 12.429688, 35.937500, 23.390625, 5.125000, 10.953125, 30.421875, 14.234375, 38.937500, 49.625000, 17.609375, 26.421875, 40.937500, 7.886719, 9.312500, 14.671875, 49.468750, 4.167969, 41.250000, 33.843750, 18.046875, 15.820312, 6.871094, 41.687500, 40.593750, 0.577148, 39.468750, 5.460938, 49.750000, 25.312500, 25.343750, 14.414062, 13.851562, 13.406250, 49.656250, 19.734375, 6.781250, 35.468750, 31.687500, 10.015625, 13.562500, 23.156250, ]\n",
      "[49.656250, 15.281250, 12.468750, 24.578125, 25.593750, 6.136719, 25.140625, 18.921875, 24.890625, 19.109375, 13.820312, 46.718750, 21.093750, 20.171875, 23.437500, 37.062500, 41.718750, 2.507812, 25.703125, 21.796875, 28.437500, 12.148438, 3.482422, 2.666016, 47.375000, 2.085938, 6.160156, 44.093750, 36.656250, 36.656250, 3.195312, 43.812500, 37.937500, 26.093750, 44.531250, 31.718750, 11.406250, 44.125000, 36.250000, 26.921875, 25.421875, 23.875000, 5.941406, 48.843750, 36.218750, 10.085938, 33.562500, 3.244141, 42.687500, 40.593750, 14.320312, 17.656250, 25.171875, 37.000000, 39.625000, 37.843750, 22.234375, 16.828125, 5.789062, 29.562500, 4.933594, 1.777344, 25.609375, 46.125000, 35.125000, 34.312500, 9.257812, 13.515625, 36.531250, 9.468750, 29.375000, 24.750000, 32.000000, 3.095703, 32.937500, 43.375000, 47.156250, 31.421875, 4.808594, 18.000000, 25.250000, 46.031250, 4.734375, 16.500000, 30.859375, 49.218750, 28.906250, 15.820312, 40.312500, 17.953125, 36.562500, 0.107300, 7.640625, 24.140625, 14.281250, 0.169556, 5.695312, 40.312500, 19.343750, 4.070312, 5.855469, 10.617188, 21.937500, 35.437500, 37.250000, 25.421875, 11.218750, 30.609375, 24.984375, 43.781250, 16.359375, 30.468750, 19.343750, 14.804688, 26.562500, 49.718750, 30.125000, 18.656250, 35.343750, 18.453125, 48.593750, 35.406250, 34.500000, 37.062500, 38.812500, 43.625000, 16.781250, 36.187500, ]\n",
      "[42.375000, 4.121094, 32.125000, 8.109375, 34.906250, 25.437500, 7.953125, 28.250000, 12.804688, 45.375000, 42.625000, 39.343750, 33.312500, 8.742188, 38.437500, 46.500000, 49.687500, 47.312500, 48.718750, 45.625000, 35.593750, 49.125000, 24.750000, 12.429688, 47.218750, 26.859375, 38.687500, 14.906250, 41.125000, 28.421875, 27.218750, 31.500000, 14.687500, 20.390625, 21.750000, 1.003906, 38.468750, 22.296875, 30.718750, 19.343750, 5.949219, 19.015625, 18.234375, 31.296875, 22.296875, 16.625000, 19.953125, 8.914062, 25.312500, 18.125000, 48.062500, 18.609375, 47.937500, 5.058594, 26.218750, 6.687500, 11.250000, 49.250000, 36.437500, 16.375000, 4.875000, 18.656250, 6.714844, 10.757812, 37.375000, 22.578125, 11.492188, 22.234375, 34.937500, 30.765625, 1.385742, 31.765625, 37.500000, 21.234375, 22.796875, 37.718750, 47.312500, 14.046875, 8.750000, 0.478027, 17.406250, 39.312500, 41.750000, 35.593750, 22.687500, 10.812500, 31.937500, 23.046875, 12.101562, 22.468750, 47.937500, 5.656250, 34.000000, 30.562500, 10.085938, 6.339844, 46.281250, 40.968750, 27.171875, 6.132812, 24.125000, 12.265625, 41.343750, 37.656250, 38.250000, 2.562500, 49.687500, 20.390625, 19.562500, 18.906250, 1.600586, 32.656250, 1.777344, 43.468750, 18.875000, 4.300781, 11.601562, 29.500000, 48.218750, 37.687500, 24.062500, 8.695312, 27.296875, 25.171875, 24.421875, 17.531250, 26.750000, 4.378906, ]\n",
      "[29.906250, 22.953125, 29.171875, 45.281250, 39.906250, 34.281250, 21.890625, 45.406250, 4.960938, 18.703125, 23.625000, 34.781250, 14.953125, 36.437500, 4.644531, 4.640625, 46.218750, 22.453125, 19.562500, 48.375000, 9.539062, 15.945312, 22.906250, 33.343750, 4.863281, 36.093750, 40.125000, 30.109375, 19.015625, 5.421875, 40.625000, 42.750000, 46.843750, 26.812500, 35.531250, 29.328125, 47.375000, 39.781250, 2.335938, 16.546875, 28.031250, 10.718750, 7.976562, 42.500000, 17.546875, 47.062500, 29.875000, 38.562500, 5.117188, 27.734375, 46.500000, 28.546875, 45.343750, 18.250000, 46.531250, 46.156250, 20.265625, 39.656250, 18.609375, 43.781250, 29.828125, 48.593750, 40.093750, 31.640625, 35.625000, 28.593750, 45.062500, 45.218750, 17.625000, 0.097778, 17.921875, 37.656250, 12.523438, 21.531250, 13.156250, 34.281250, 45.812500, 46.937500, 14.546875, 31.765625, 18.828125, 41.750000, 3.792969, 29.031250, 3.781250, 34.875000, 49.937500, 12.804688, 13.406250, 32.218750, 49.875000, 39.406250, 1.608398, 37.968750, 13.953125, 4.433594, 41.218750, 39.968750, 48.937500, 26.125000, 17.187500, 14.304688, 27.078125, 37.781250, 34.750000, 5.511719, 48.843750, 12.085938, 32.187500, 31.500000, 41.156250, 49.562500, 17.781250, 14.187500, 11.406250, 43.375000, 37.437500, 8.218750, 9.554688, 42.562500, 10.242188, 42.687500, 5.851562, 10.250000, 17.359375, 12.875000, 15.210938, 49.687500, ]\n",
      "[32.531250, 24.484375, 42.000000, 37.062500, 40.250000, 45.437500, 47.250000, 37.031250, 16.062500, 24.828125, 25.921875, 39.125000, 33.718750, 24.156250, 36.656250, 36.531250, 32.187500, 21.046875, 4.484375, 7.832031, 42.906250, 17.953125, 38.937500, 15.078125, 15.078125, 25.359375, 21.031250, 16.828125, 1.243164, 1.358398, 36.781250, 43.343750, 43.406250, 29.812500, 31.328125, 11.132812, 42.250000, 1.025391, 26.875000, 19.906250, 35.218750, 38.187500, 7.847656, 45.562500, 26.265625, 36.187500, 18.937500, 38.906250, 23.500000, 20.671875, 1.069336, 21.187500, 47.187500, 39.437500, 38.062500, 18.062500, 18.609375, 17.921875, 13.796875, 45.593750, 27.562500, 37.343750, 29.093750, 45.218750, 42.156250, 39.343750, 19.468750, 37.562500, 42.593750, 24.531250, 3.505859, 12.718750, 37.062500, 24.421875, 34.656250, 10.671875, 3.558594, 15.476562, 21.703125, 32.187500, 37.187500, 5.757812, 32.875000, 22.296875, 21.953125, 45.218750, 22.328125, 8.976562, 26.953125, 12.937500, 27.937500, 36.531250, 2.578125, 25.265625, 9.515625, 5.292969, 20.250000, 2.201172, 34.250000, 1.982422, 8.132812, 9.890625, 36.468750, 28.765625, 26.984375, 17.156250, 46.125000, 22.796875, 31.218750, 42.343750, 23.296875, 4.023438, 13.601562, 26.531250, 25.468750, 22.015625, 28.343750, 12.570312, 2.716797, 21.437500, 15.500000, 24.968750, 12.843750, 5.417969, 12.937500, 11.617188, 42.562500, 27.375000, ]\n",
      "[18.453125, 6.281250, 46.125000, 46.468750, 10.148438, 18.609375, 22.312500, 10.601562, 22.500000, 21.296875, 5.218750, 10.453125, 26.390625, 23.140625, 27.687500, 30.718750, 21.796875, 4.960938, 23.531250, 32.343750, 42.218750, 32.875000, 7.886719, 36.875000, 12.539062, 22.828125, 46.062500, 39.125000, 1.788086, 49.250000, 0.700195, 32.250000, 19.125000, 38.281250, 15.945312, 31.390625, 0.985840, 5.640625, 41.125000, 40.593750, 15.476562, 17.328125, 22.593750, 47.156250, 1.884766, 4.765625, 24.359375, 45.218750, 29.343750, 27.703125, 36.500000, 16.468750, 1.360352, 44.812500, 20.234375, 17.937500, 17.875000, 34.000000, 33.531250, 25.046875, 32.937500, 13.992188, 35.781250, 18.484375, 11.140625, 35.062500, 12.281250, 43.562500, 49.750000, 31.125000, 25.000000, 44.031250, 8.742188, 41.593750, 41.062500, 37.468750, 35.062500, 31.812500, 30.421875, 49.375000, 19.187500, 12.062500, 14.171875, 13.937500, 44.156250, 7.140625, 12.296875, 23.250000, 41.031250, 8.687500, 34.750000, 49.125000, 35.093750, 39.312500, 17.515625, 15.773438, 12.484375, 25.968750, 23.578125, 11.664062, 4.539062, 22.187500, 0.143188, 26.515625, 34.125000, 49.031250, 12.382812, 15.296875, 8.515625, 24.718750, 28.375000, 37.437500, 45.718750, 40.468750, 44.812500, 5.226562, 44.250000, 19.234375, 28.125000, 39.968750, 27.390625, 29.937500, 3.988281, 1.187500, 0.273438, 7.804688, 9.710938, 21.125000, ]]\n",
      "\n",
      "P_s before shifted exp:\n",
      "[[inf, inf, inf, inf, inf, inf, inf, inf, ]\n",
      "[inf, inf, inf, inf, inf, inf, inf, inf, ]\n",
      "[inf, inf, inf, inf, inf, inf, inf, inf, ]\n",
      "[inf, inf, inf, inf, inf, inf, inf, inf, ]\n",
      "[inf, inf, inf, inf, inf, inf, inf, inf, ]\n",
      "[inf, inf, inf, inf, inf, inf, inf, inf, ]\n",
      "[inf, inf, inf, inf, inf, inf, inf, inf, ]\n",
      "[inf, inf, inf, inf, inf, inf, inf, inf, ]]\n",
      "\n",
      "P_s after shifted exp:\n",
      "[[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]]\n",
      "\n",
      "p_s should be the same as before\n",
      "[[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]]\n",
      "\n",
      "V_s is:\n",
      "[[40.281250, 23.593750, 25.468750, 24.031250, 23.359375, 36.250000, 16.593750, 16.328125, 9.609375, 32.437500, 35.531250, 39.656250, 15.953125, 42.406250, 15.453125, 18.859375, 8.171875, 2.130859, 41.031250, 19.984375, 33.093750, 44.093750, 40.812500, 45.906250, 18.109375, 35.312500, 31.781250, 36.312500, 2.521484, 30.859375, 24.406250, 47.406250, 43.750000, 31.734375, 4.890625, 10.203125, 35.781250, 6.269531, 9.484375, 6.683594, 20.781250, 21.562500, 39.437500, 28.609375, 8.656250, 44.625000, 29.390625, 6.707031, 14.218750, 25.531250, 49.500000, 30.718750, 3.470703, 33.593750, 6.281250, 37.406250, 45.562500, 19.171875, 48.906250, 47.500000, 5.445312, 32.656250, 31.640625, 31.562500, 16.828125, 36.406250, 1.335938, 34.312500, 29.328125, 25.906250, 5.835938, 15.273438, 13.742188, 43.750000, 42.531250, 6.628906, 15.820312, 12.734375, 16.828125, 3.310547, 18.343750, 32.375000, 1.183594, 21.890625, 13.195312, 11.929688, 34.937500, 10.171875, 18.875000, 21.734375, 0.264160, 8.109375, 39.375000, 44.468750, 20.468750, 10.015625, 44.843750, 13.070312, 14.218750, 45.781250, 25.031250, 10.304688, 37.031250, 14.023438, 1.440430, 49.218750, 35.062500, 6.382812, 15.976562, 30.859375, 18.609375, 19.671875, 42.562500, 33.500000, 42.562500, 23.437500, 16.468750, 24.000000, 48.593750, 33.156250, 11.945312, 49.062500, 25.812500, 30.437500, 24.250000, 18.250000, 14.359375, 14.101562, ]\n",
      "[43.250000, 26.468750, 10.007812, 6.628906, 20.828125, 39.312500, 7.289062, 20.984375, 6.847656, 13.851562, 5.335938, 39.531250, 26.593750, 5.699219, 27.984375, 41.562500, 16.718750, 39.625000, 47.500000, 48.093750, 1.773438, 18.500000, 29.250000, 33.750000, 23.890625, 23.187500, 24.015625, 32.156250, 13.390625, 7.585938, 35.781250, 5.199219, 24.328125, 42.906250, 12.632812, 1.839844, 37.375000, 15.796875, 41.781250, 0.584961, 21.062500, 25.609375, 12.015625, 10.382812, 26.093750, 47.062500, 33.468750, 42.562500, 5.531250, 0.061981, 15.429688, 45.031250, 29.781250, 6.566406, 12.609375, 46.812500, 41.125000, 48.281250, 14.773438, 5.738281, 46.218750, 11.562500, 19.640625, 3.156250, 47.062500, 47.593750, 27.703125, 3.494141, 10.460938, 32.687500, 18.718750, 41.281250, 5.191406, 8.132812, 40.218750, 43.125000, 40.156250, 44.218750, 30.125000, 17.468750, 23.156250, 9.945312, 21.500000, 30.859375, 3.476562, 31.640625, 27.218750, 39.375000, 5.414062, 49.531250, 19.531250, 14.781250, 5.984375, 22.578125, 49.281250, 24.968750, 43.250000, 17.109375, 20.875000, 47.875000, 2.671875, 44.843750, 2.849609, 44.875000, 37.312500, 0.075989, 43.062500, 24.578125, 14.664062, 6.867188, 36.218750, 12.562500, 44.375000, 9.414062, 23.953125, 29.375000, 25.140625, 11.796875, 25.734375, 48.750000, 16.734375, 39.406250, 28.859375, 35.437500, 9.140625, 47.062500, 26.437500, 6.398438, ]\n",
      "[47.593750, 35.062500, 12.960938, 39.625000, 7.648438, 22.750000, 43.843750, 12.875000, 29.203125, 38.031250, 35.093750, 40.000000, 29.343750, 25.593750, 36.718750, 19.843750, 32.156250, 31.640625, 11.804688, 4.519531, 7.031250, 43.843750, 22.312500, 19.109375, 40.218750, 19.562500, 36.093750, 0.277344, 40.000000, 15.078125, 42.843750, 8.601562, 25.750000, 27.203125, 32.718750, 25.828125, 35.875000, 9.343750, 11.117188, 49.375000, 46.937500, 16.156250, 48.187500, 5.281250, 37.843750, 7.640625, 24.171875, 20.359375, 1.971680, 35.156250, 44.125000, 28.296875, 41.718750, 5.046875, 19.718750, 5.199219, 42.968750, 0.294434, 28.984375, 36.656250, 24.812500, 37.968750, 14.664062, 9.500000, 9.296875, 18.250000, 19.609375, 22.515625, 13.304688, 47.187500, 3.644531, 34.718750, 34.093750, 2.808594, 4.457031, 25.390625, 23.203125, 45.812500, 1.736328, 29.046875, 13.429688, 7.250000, 39.562500, 18.453125, 17.500000, 7.332031, 47.250000, 33.687500, 15.773438, 5.210938, 9.546875, 36.156250, 41.906250, 18.890625, 16.140625, 20.968750, 26.312500, 43.750000, 43.187500, 43.125000, 47.812500, 12.890625, 38.125000, 8.484375, 3.589844, 48.812500, 18.109375, 14.218750, 44.468750, 10.070312, 18.000000, 1.256836, 38.343750, 43.218750, 37.062500, 23.406250, 8.929688, 48.218750, 49.625000, 45.593750, 46.843750, 25.125000, 22.421875, 13.585938, 5.183594, 48.875000, 7.531250, 26.859375, ]\n",
      "[21.765625, 49.531250, 5.300781, 41.906250, 17.687500, 16.875000, 7.312500, 40.812500, 26.031250, 40.250000, 34.218750, 47.375000, 3.500000, 9.859375, 12.929688, 24.328125, 45.937500, 9.726562, 3.869141, 4.007812, 5.585938, 37.000000, 7.542969, 34.062500, 7.378906, 8.875000, 13.046875, 24.593750, 28.984375, 46.031250, 15.757812, 26.171875, 34.531250, 44.500000, 18.281250, 21.312500, 44.625000, 18.718750, 1.658203, 41.343750, 21.453125, 25.171875, 37.625000, 49.281250, 5.058594, 44.687500, 23.906250, 5.882812, 39.968750, 0.801270, 15.296875, 4.804688, 40.687500, 4.066406, 19.093750, 35.718750, 8.335938, 38.187500, 40.937500, 48.500000, 30.984375, 40.843750, 4.289062, 1.509766, 22.515625, 40.625000, 36.656250, 1.939453, 17.000000, 16.406250, 46.937500, 42.093750, 42.812500, 35.250000, 37.593750, 32.562500, 33.187500, 24.578125, 19.312500, 44.500000, 7.640625, 33.593750, 44.687500, 45.031250, 17.156250, 33.812500, 46.312500, 15.625000, 12.523438, 43.843750, 12.062500, 36.656250, 19.171875, 38.437500, 36.562500, 6.000000, 19.171875, 12.609375, 20.546875, 14.820312, 25.250000, 48.500000, 32.718750, 2.230469, 16.640625, 24.828125, 14.906250, 40.281250, 46.375000, 35.468750, 34.031250, 16.875000, 48.812500, 34.750000, 28.031250, 13.500000, 28.953125, 30.203125, 8.804688, 25.640625, 17.562500, 10.398438, 10.562500, 5.703125, 38.156250, 49.375000, 1.874023, 3.148438, ]\n",
      "[34.937500, 37.406250, 14.382812, 1.527344, 45.750000, 33.875000, 11.453125, 37.125000, 18.562500, 20.171875, 21.062500, 39.687500, 47.250000, 21.328125, 20.734375, 38.218750, 23.906250, 25.265625, 25.828125, 12.515625, 35.437500, 20.578125, 34.093750, 3.726562, 30.984375, 1.846680, 17.046875, 35.843750, 26.781250, 32.687500, 11.656250, 6.816406, 7.343750, 20.187500, 33.593750, 38.375000, 11.320312, 48.500000, 37.562500, 21.281250, 46.750000, 10.296875, 16.265625, 41.812500, 41.437500, 35.562500, 24.281250, 47.875000, 29.734375, 42.906250, 20.734375, 14.671875, 33.843750, 2.470703, 6.089844, 13.015625, 46.812500, 11.546875, 17.875000, 16.890625, 47.031250, 10.343750, 15.101562, 40.718750, 42.031250, 32.281250, 4.250000, 29.781250, 38.218750, 4.851562, 15.500000, 41.812500, 22.875000, 30.984375, 7.628906, 23.125000, 21.921875, 26.656250, 19.562500, 42.843750, 11.289062, 27.031250, 6.347656, 0.120850, 29.500000, 43.093750, 29.765625, 0.233032, 32.906250, 46.875000, 20.156250, 7.531250, 13.265625, 35.656250, 12.351562, 45.031250, 35.062500, 29.046875, 14.734375, 24.250000, 24.750000, 35.093750, 12.046875, 18.125000, 14.132812, 30.250000, 9.726562, 38.687500, 27.343750, 45.562500, 10.023438, 19.406250, 27.984375, 19.953125, 23.968750, 49.718750, 36.875000, 9.359375, 3.093750, 1.216797, 38.218750, 0.054932, 31.765625, 26.312500, 17.937500, 8.414062, 35.000000, 32.093750, ]\n",
      "[11.460938, 43.031250, 4.570312, 27.984375, 22.609375, 34.062500, 35.406250, 19.250000, 21.203125, 15.171875, 41.468750, 39.750000, 44.531250, 41.562500, 21.828125, 3.001953, 38.781250, 20.093750, 5.867188, 48.125000, 32.562500, 30.078125, 25.531250, 3.140625, 10.890625, 22.546875, 9.671875, 1.215820, 39.562500, 35.125000, 12.914062, 14.632812, 14.500000, 9.257812, 34.250000, 37.156250, 47.968750, 12.195312, 1.153320, 20.671875, 24.218750, 30.000000, 28.984375, 11.234375, 12.218750, 10.273438, 30.515625, 35.375000, 1.597656, 44.687500, 29.093750, 6.773438, 41.593750, 14.195312, 43.437500, 9.187500, 18.937500, 35.312500, 18.828125, 43.687500, 25.078125, 46.687500, 11.640625, 17.328125, 49.187500, 0.143677, 39.687500, 4.117188, 13.210938, 33.531250, 31.156250, 24.062500, 40.718750, 49.281250, 10.031250, 0.743652, 42.500000, 23.765625, 44.375000, 33.937500, 39.375000, 13.656250, 12.523438, 3.726562, 8.671875, 33.062500, 24.687500, 16.703125, 3.787109, 27.390625, 49.437500, 32.968750, 14.609375, 0.401367, 24.125000, 47.156250, 5.839844, 18.390625, 11.648438, 46.781250, 21.718750, 7.843750, 36.125000, 13.671875, 14.937500, 2.125000, 18.625000, 31.171875, 46.562500, 40.093750, 44.375000, 45.375000, 41.468750, 38.562500, 22.218750, 21.015625, 47.937500, 29.859375, 1.313477, 13.929688, 0.429199, 34.625000, 27.812500, 11.765625, 38.343750, 16.484375, 15.929688, 6.593750, ]\n",
      "[29.953125, 39.687500, 2.162109, 34.343750, 39.937500, 24.843750, 41.343750, 39.062500, 37.875000, 38.593750, 36.093750, 35.937500, 26.531250, 42.437500, 0.229492, 7.847656, 2.748047, 17.500000, 40.062500, 30.031250, 28.859375, 46.656250, 25.781250, 28.828125, 26.218750, 43.718750, 39.281250, 14.734375, 14.015625, 20.796875, 9.500000, 13.906250, 40.812500, 19.703125, 11.750000, 46.687500, 27.000000, 4.453125, 14.632812, 21.531250, 37.093750, 11.078125, 26.640625, 3.455078, 49.750000, 29.421875, 41.000000, 30.000000, 3.603516, 36.437500, 29.546875, 15.710938, 13.929688, 26.375000, 9.195312, 21.375000, 4.710938, 31.156250, 15.835938, 43.468750, 37.437500, 26.640625, 14.218750, 4.527344, 19.218750, 25.875000, 0.024628, 18.984375, 19.500000, 37.500000, 17.109375, 41.562500, 16.000000, 2.957031, 11.382812, 31.734375, 21.062500, 42.843750, 22.515625, 30.859375, 42.968750, 15.601562, 21.625000, 34.281250, 21.531250, 34.812500, 47.500000, 17.671875, 18.171875, 1.306641, 20.093750, 45.906250, 11.632812, 6.046875, 25.687500, 37.281250, 16.171875, 45.531250, 29.296875, 6.046875, 38.187500, 3.222656, 7.105469, 15.000000, 32.437500, 2.849609, 32.468750, 32.156250, 35.656250, 17.078125, 22.187500, 10.671875, 48.625000, 1.960938, 28.250000, 40.000000, 36.562500, 45.593750, 34.625000, 41.812500, 22.187500, 46.187500, 43.500000, 10.132812, 15.445312, 33.187500, 45.593750, 21.375000, ]\n",
      "[47.687500, 47.250000, 5.617188, 38.250000, 7.117188, 4.597656, 40.000000, 20.828125, 48.937500, 27.437500, 40.281250, 28.031250, 27.468750, 40.343750, 47.250000, 16.593750, 35.375000, 8.507812, 3.519531, 21.437500, 12.867188, 4.023438, 35.468750, 16.046875, 9.164062, 23.078125, 46.718750, 20.234375, 42.562500, 20.718750, 48.375000, 7.019531, 1.623047, 17.312500, 46.968750, 24.812500, 18.984375, 38.531250, 1.183594, 34.656250, 47.625000, 46.750000, 37.437500, 46.937500, 23.375000, 10.390625, 18.406250, 30.640625, 14.562500, 26.953125, 13.968750, 38.843750, 5.839844, 14.000000, 48.281250, 42.468750, 0.948242, 41.281250, 45.062500, 24.656250, 39.343750, 18.218750, 34.187500, 34.625000, 8.734375, 44.937500, 26.250000, 12.093750, 40.156250, 42.156250, 9.171875, 7.203125, 46.593750, 6.355469, 33.468750, 33.343750, 21.906250, 38.656250, 15.445312, 10.890625, 29.656250, 25.703125, 44.250000, 6.953125, 5.363281, 45.781250, 38.000000, 2.775391, 32.437500, 22.640625, 2.312500, 0.577148, 30.593750, 11.609375, 8.187500, 4.335938, 9.867188, 30.984375, 21.281250, 13.460938, 19.703125, 47.500000, 31.859375, 39.218750, 27.984375, 14.890625, 15.109375, 13.718750, 25.703125, 0.200806, 24.062500, 31.343750, 4.031250, 4.507812, 1.853516, 7.402344, 36.406250, 4.914062, 14.625000, 22.375000, 49.281250, 10.531250, 27.265625, 27.093750, 39.125000, 38.906250, 26.468750, 34.625000, ]]\n",
      "\n",
      "[[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]\n",
      "[-nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, -nan, ]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[47.6875, 47.2500,  5.6172,  ..., 38.9062, 26.4688, 34.6250],\n",
       "         [47.6875, 47.2500,  5.6172,  ..., 38.9062, 26.4688, 34.6250],\n",
       "         [29.9531, 39.6875,  2.1621,  ..., 33.1875, 45.5938, 21.3750],\n",
       "         ...,\n",
       "         [43.2500, 26.4688, 10.0078,  ..., 47.0625, 26.4375,  6.3984],\n",
       "         [43.2500, 26.4688, 10.0078,  ..., 47.0625, 26.4375,  6.3984],\n",
       "         [43.2500, 26.4688, 10.0078,  ..., 47.0625, 26.4375,  6.3984]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
       "        dtype=torch.float16))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.isclose(dumb_attn(Q, K, V), flashattn(Q, K, V))\n",
    "# dumb_attn(Q, K, V), flashattn(Q, K, V)\n",
    "\n",
    "# F.scaled_dot_product_attention(Q, K, V, scale=1), flashattn(Q, K, V)\n",
    "# module.flash_attn(Q, K, V)\n",
    "r1 = dumb_attn(Q, K, V)\n",
    "r2 = module.flash_attn(Q, K, V)\n",
    "(r1-r2).abs().mean()\n",
    "r1, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4., 4., 3., 1., 5.]),\n",
       " tensor([4., 4., 3., 1., 5., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(1, 9, (5,)).float()\n",
    "b = torch.hstack((a, torch.zeros((5,)).float()))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1947, 0.1947, 0.0716, 0.0097, 0.5293]),\n",
       " tensor([0.1913, 0.1913, 0.0704, 0.0095, 0.5200, 0.0035, 0.0035, 0.0035, 0.0035,\n",
       "         0.0035]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.softmax(0), b.softmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0.0000,     0.0000,     0.0183,     1.0000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([65.000000, 42.000000, 80.000000, 84.000000], dtype=torch.float32)\n",
    "(a - a.max()).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
